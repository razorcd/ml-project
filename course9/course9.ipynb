{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "714796d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clothing-model.tflite  course9.py  model.tflite  __pycache__\n",
      "course9.ipynb\t       Dockerfile  pants.jpg\t xception_v01_08_0.839.h5\n",
      "tensorflow version 2.6.0\n",
      "Python 3.8.8\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"tensorflow version\",tf.__version__)\n",
    "!python -V\n",
    "\n",
    "\n",
    "model = keras.models.load_model('xception_v01_08_0.839.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e659f2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (1, 150, 150, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dress': -4.5231104,\n",
       " 'hat': -8.803727,\n",
       " 'longsleeve': -3.5136056,\n",
       " 'outwear': -0.27382424,\n",
       " 'pants': 7.5560517,\n",
       " 'shirt': -5.391409,\n",
       " 'shoes': -8.340543,\n",
       " 'shorts': -0.9096003,\n",
       " 'skirt': -5.358587,\n",
       " 't-shirt': -7.7458005}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "img = load_img('pants.jpg', target_size=(150,150))\n",
    "\n",
    "x = np.array(img)\n",
    "X = np.array([x])\n",
    "\n",
    "X = preprocess_input(X)\n",
    "print(\"Image shape:\", X.shape)\n",
    "\n",
    "pred = model.predict(X)\n",
    "\n",
    "classes = [\"dress\", \"hat\", \"longsleeve\", \"outwear\", \"pants\", \"shirt\", \"shoes\", \"shorts\", \"skirt\", \"t-shirt\"]\n",
    "dict(zip(classes, pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7f1bd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpp36b6tcz/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cristiandugacicu/anaconda3/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 244688\r\n",
      "drwxrwxr-x  4 cristiandugacicu cristiandugacicu     4096 Nov 26 21:39 .\r\n",
      "drwxrwxr-x 12 cristiandugacicu cristiandugacicu     4096 Nov 25 21:06 ..\r\n",
      "-rw-rw-r--  1 cristiandugacicu cristiandugacicu 83258180 Nov 26 21:40 clothing-model.tflite\r\n",
      "-rw-rw-r--  1 cristiandugacicu cristiandugacicu     8686 Nov 26 21:39 course9.ipynb\r\n",
      "-rw-rw-r--  1 cristiandugacicu cristiandugacicu     1784 Nov 26 21:38 course9.py\r\n",
      "-rw-rw-r--  1 cristiandugacicu cristiandugacicu      376 Nov 26 21:30 Dockerfile\r\n",
      "drwxrwxr-x  2 cristiandugacicu cristiandugacicu     4096 Nov 25 21:20 .ipynb_checkpoints\r\n",
      "-rw-rw-r--  1 cristiandugacicu cristiandugacicu 83258180 Nov 25 21:20 model.tflite\r\n",
      "-rw-rw-r--  1 cristiandugacicu cristiandugacicu    27143 Nov 25 21:12 pants.jpg\r\n",
      "drwxrwxr-x  2 cristiandugacicu cristiandugacicu     4096 Nov 26 20:44 __pycache__\r\n",
      "-rw-rw-r--  1 cristiandugacicu cristiandugacicu 83963280 Nov 25 21:07 xception_v01_08_0.839.h5\r\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow Lite coverter from TensorFlow\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tf_lite_model = converter.convert()\n",
    "\n",
    "with open('clothing-model.tflite', 'wb') as f_out:\n",
    "    f_out.write(tf_lite_model)\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1297be5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "generic_type: type \"InterpreterWrapper\" is already registered!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4a9eaa91bb9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# import tensorflow.lite as tflite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtflite_runtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpreter\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtflite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# interpreter = tflite.Interpreter(model_path='clothing-model.tflite')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tflite_runtime/interpreter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;31m# This file is part of tflite_runtime package.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtflite_runtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_tensorflow_interpreter_wrapper\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_interpreter_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtflite_runtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics_portable\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: generic_type: type \"InterpreterWrapper\" is already registered!"
     ]
    }
   ],
   "source": [
    "# Load TensorFlow Lite model\n",
    "# !pip install https://github.com/alexeygrigorev/tflite-aws-lambda/raw/main/tflite/tflite_runtime-2.7.0-cp38-cp38-linux_x86_64.whl\n",
    "\n",
    "# import tensorflow.lite as tflite\n",
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "interpreter = tflite.Interpreter(model_path='clothing-model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "print(\"Input details:\")\n",
    "display(interpreter.get_input_details())\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "\n",
    "print(\"Output details:\")\n",
    "display(interpreter.get_output_details())\n",
    "output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "\n",
    "interpreter.set_tensor(input_index, X)\n",
    "interpreter.invoke()\n",
    "\n",
    "\n",
    "preds = interpreter.get_tensor(output_index)\n",
    "\n",
    "dict(zip(classes,  preds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fbfd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified way for TensorFlow Lite\n",
    "\n",
    "# !pip install keras_image_helper\n",
    "from keras_image_helper import create_preprocessor\n",
    "\n",
    "preprocessor = create_preprocessor('xception', target_size=(150,150))\n",
    "X = preprocessor.from_path('pants.jpg')\n",
    "\n",
    "interpreter.set_tensor(input_index, X)\n",
    "interpreter.invoke()\n",
    "\n",
    "\n",
    "preds = interpreter.get_tensor(output_index)\n",
    "\n",
    "dict(zip(classes,  preds[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
